---
title: 'Book Notes: Flexible Imputation of Missing Data -- Ch4 Multivariate Missing
  Data'
author: ''
date: '2020-08-25'
slug: book-notes-flexible-imputation-of-missing-data-ch4-multivariate-missing-data
categories:
  - Book notes
tags:
  - Introduction
  - Missing data
  - Slides
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---


<div id="TOC">
<ul>
<li><a href="#missing-data-pattern">Missing Data Pattern</a></li>
<li><a href="#fully-conditional-specification-fcs">Fully Conditional Specification (FCS)</a></li>
</ul>
</div>

<p><strong><em>For the pdf slides, click <a href="/pdf/081320_imputation_book_ch4.pdf">here</a></em></strong></p>
<div id="notations-in-this-chapter" class="section level3">
<h3>Notations in this chapter</h3>
<ul>
<li><span class="math inline">\(Y\)</span>: a <span class="math inline">\(n \times p\)</span> matrix which contains is missing data</li>
<li><span class="math inline">\(Y_j\)</span>: the <span class="math inline">\(j\)</span>th column in <span class="math inline">\(Y\)</span></li>
<li><span class="math inline">\(Y_{-j}\)</span>: all but the <span class="math inline">\(j\)</span>th column of <span class="math inline">\(Y\)</span></li>
<li><span class="math inline">\(R\)</span>: a <span class="math inline">\(n \times p\)</span> missing indicator matrix
<ul>
<li><span class="math inline">\(0\)</span> is missing and <span class="math inline">\(1\)</span> is observed</li>
</ul></li>
</ul>
</div>
<div id="missing-data-pattern" class="section level1">
<h1>Missing Data Pattern</h1>
<div id="missing-data-pattern-summary-statistics" class="section level3">
<h3>Missing data pattern summary statistics</h3>
<ul>
<li>When the number of columns is small, we can use the <code>md.pattern</code> function in <code>mice</code> to get missing data counts of all combinations among columns</li>
</ul>
<pre class="r"><code>library(mice); 
md.pattern(pattern4, plot = FALSE)</code></pre>
<pre><code>##   A B C  
## 2 1 1 1 0
## 3 1 1 0 1
## 1 1 0 1 1
## 2 0 0 1 2
##   2 3 3 8</code></pre>
<ul>
<li>When the number of columns is large, we can use the <code>md.pairs</code> function in <code>mice</code> to check the counts of each of the four pairwise missingness patterns (<code>rr</code>, <code>rm</code>, <code>mr</code>, and <code>mm</code>)</li>
</ul>
</div>
<div id="inbound-and-outbound-statistics-measure-pairwise-missing-patterns" class="section level3">
<h3>Inbound and outbound statistics: measure pairwise missing patterns</h3>
<ul>
<li><font color='blue'>Proportion of usable cases, i.e., inbound statistics</font> for imputing variable <span class="math inline">\(Y_j\)</span> from variable <span class="math inline">\(Y_k\)</span>:
total cases where <span class="math inline">\(Y_j\)</span> is missing but <span class="math inline">\(Y_k\)</span> is observed over total missings in <span class="math inline">\(Y_j\)</span>
<span class="math display">\[
I_{jk} = \frac{\sum_{i=1}^n (1 - r_{ij}) r_{ik}}{\sum_{i=1}^n (1 - r_{ij})}
\]</span>
<ul>
<li>When imputing <span class="math inline">\(X_j\)</span>, we can use this statistic to quickly identify which variables to use</li>
</ul></li>
<li><font color='blue'>Outbound statistic</font> measures how observed data in <span class="math inline">\(Y_j\)</span> connect to the missing data in <span class="math inline">\(Y_k\)</span>
<span class="math display">\[
O_{jk} = \frac{\sum_{i=1}^n r_{ij} (1 - r_{ik})}{\sum_{i=1}^n r_{ij}}
\]</span></li>
</ul>
</div>
<div id="different-imputation-strategies-for-different-missing-patterns" class="section level3">
<h3>Different imputation strategies for different missing patterns</h3>
<ul>
<li><p>Monotone data imputation</p>
<ul>
<li>for monotone missing data pattern</li>
<li>imputations are created by a sequence of univariate methods</li>
</ul></li>
<li><p>Joint modeling (JM)</p>
<ul>
<li>for general missing patterns,</li>
<li>imputations are created by multivariate models</li>
</ul></li>
<li><p>Fully conditional specification (FCS, aka chained equations)</p>
<ul>
<li>for general missing patterns,</li>
<li>imputations are drawn from iterated conditional univarate models</li>
<li><font color='green'>Usually, FCS is found better than JM</font></li>
</ul></li>
<li><p>Block of variables, hybrid imputation between JM and FCS</p></li>
</ul>
</div>
<div id="monotone-data-imputation" class="section level3">
<h3>Monotone data imputation</h3>
<ul>
<li><p>A <font color='blue'>monotone missing pattern</font>: the columns of <span class="math inline">\(Y\)</span> can be ordered such that
for any row, if <span class="math inline">\(Y_j\)</span> is missing, then all columns to the right of <span class="math inline">\(Y_j\)</span> are also missing</p></li>
<li><p>Suppose the variables with missings are ordered as <span class="math inline">\(Y_1, Y_2, \ldots, Y_p\)</span>, and
the variables without missings are denoted as <span class="math inline">\(X\)</span>. Then the <font color='blue'>monotone missing imputation</font> is</p>
<ul>
<li>Impute <span class="math inline">\(Y_1\)</span> from <span class="math inline">\(X\)</span></li>
<li>Impute <span class="math inline">\(Y_2\)</span> from <span class="math inline">\((Y_1, X)\)</span></li>
<li>…</li>
<li>Impute <span class="math inline">\(Y_p\)</span> from <span class="math inline">\((Y_1, \ldots, Y_{p-1}, X)\)</span></li>
</ul></li>
</ul>
</div>
</div>
<div id="fully-conditional-specification-fcs" class="section level1">
<h1>Fully Conditional Specification (FCS)</h1>
<div id="fully-conditional-sepcification-fcs-similar-to-gibbs-sampling" class="section level3">
<h3><font color='blue'>Fully conditional sepcification (FCS)</font>: <font color='green'>similar to Gibbs sampling</font></h3>
<ul>
<li><p>FCS specifies the multivariate distribution <span class="math inline">\(p(Y, X, R\mid \theta)\)</span> through a set of conditional densities
<span class="math inline">\(p(Y_j \mid X, Y_{-j}, R, \phi_j)\)</span></p></li>
<li>The conditional density is used to impute <span class="math inline">\(Y_j\)</span> given <span class="math inline">\(X, Y_{-j}, R\)</span> (including the most recent imputed values).
<span class="math display">\[\begin{align*}
\dot{\phi}_j &amp; \sim p(\phi_j \mid Y_j^\text{obs}, \dot{Y}_{-j}, R)\\
\dot{Y}_j &amp; \sim p(Y_j^\text{mis}\mid Y_j^\text{obs}, \dot{Y}_{-j}, R, \phi_j)
\end{align*}\]</span>
<ul>
<li>We can use the univariate imputation method introduced in Chapter 3 as building blocks</li>
</ul></li>
<li>To initialize, we can impute from the marginal distributions</li>
<li>One iteration consists of one cycle through all <span class="math inline">\(Y_j\)</span>. Total number of iterations <span class="math inline">\(M\)</span> can often be low, e.g., 5, 10, or 20.</li>
<li><p>For multiple imputation, perform this process in parallel for <span class="math inline">\(m\)</span> times</p></li>
</ul>
</div>
<div id="convergence-of-fcs-and-in-general-of-a-markov-chain" class="section level3">
<h3>Convergence of FCS (and in general of a Markov chain)</h3>
<ul>
<li><p><font color='green'>Irreducible</font>: the chain must be able to reach all interesting parts of the state space</p>
<ul>
<li>Easy; users have large control over the interesting parts.</li>
</ul></li>
<li><p><font color='green'>Aperiodic</font>: the chain should not oscillate between different states</p>
<ul>
<li>A way to diagnose is to stop the chain at different points,
and make sure stopping point does not affect statistical inferences</li>
</ul></li>
<li><p><font color='green'>Recurrence</font>: all interesting parts can be reached infinitely often, at least from almost all starting points</p>
<ul>
<li>May be diagnosed from traceplots</li>
</ul></li>
</ul>
</div>
<div id="compatibility" class="section level3">
<h3>Compatibility</h3>
<ul>
<li>Two conditional densities <span class="math inline">\(p(Y_1 \mid Y_2)\)</span>, <span class="math inline">\(p(Y_2 \mid Y_1)\)</span> are <font color='blue'>compatible</font> if
<ul>
<li>a joint distribution <span class="math inline">\(p(Y_1, Y_2)\)</span> exists, and</li>
<li>it has <span class="math inline">\(p(Y_1 \mid Y_2)\)</span> and <span class="math inline">\(p(Y_2 \mid Y_1)\)</span> as its conditional densities</li>
</ul></li>
<li><p>FCS is only guaranteed to work if the conditionals are compatible</p></li>
<li><p>The MICE algorithm (the FCS implemented in <code>mice</code> package) is ignorant of the non-existence of joint distribution,
and imputes anyway.</p>
<ul>
<li>Empirical evidence suggests the estimation results may be robust against violations of compatibility</li>
</ul></li>
</ul>
</div>
<div id="number-of-fcs-iterations" class="section level3">
<h3>Number of FCS iterations</h3>
<ul>
<li><p>Why can the number of iterations in FCS be low (usually 5-20)?</p>
<ul>
<li>The imputed data <span class="math inline">\(\dot{Y}_\text{mis}\)</span> can have a considerable amount of random noise</li>
<li>Hence if the relations between the variables are not strong,
the autocorrelation over iteration may be low, and thus convergence can be rapid</li>
</ul></li>
<li><p>Watch out for the following situations:</p>
<ul>
<li>the correlations between <span class="math inline">\(Y_j\)</span>’s are high</li>
<li>missing rates are high</li>
<li>constraints on parameters across different variables exist</li>
</ul></li>
</ul>
</div>
<div id="example-of-slow-convergence-design-of-simulation" class="section level3">
<h3>Example of slow convergence: design of simulation</h3>
<ul>
<li>One completed covariate <span class="math inline">\(X\)</span> and two incomplete variables <span class="math inline">\(Y_1, Y_2\)</span></li>
<li>Data are draw from multivariate normals with correlations
<span class="math display">\[
\rho(X, Y_1) = \rho(X, Y_2) = 0.9, \quad
\rho(Y_1, Y_2) = 0.7
\]</span></li>
<li>Total sample size <span class="math inline">\(n=10000\)</span>, and completely observed cases <span class="math inline">\(\in \{1000, 500, 250, 100, 50, 0\}\)</span></li>
<li>Imputation models are normal linear regressions (PMM)</li>
</ul>
</div>
<div id="example-of-slow-convergence-traceplots" class="section level3">
<h3>Example of slow convergence: traceplots</h3>
<ul>
<li>Missing problem with high correlation and high missing rates: convergence is poor</li>
</ul>
<p><img src="/figures/flexible_imputation_fig4_3.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<ul>
<li><p>Van Buuren, S. (2018). Flexible Imputation of Missing Data, 2nd Edition. CRC press.</p>
<ul>
<li><a href="https://stefvanbuuren.name/fimd/" class="uri">https://stefvanbuuren.name/fimd/</a></li>
</ul></li>
</ul>
</div>
</div>
