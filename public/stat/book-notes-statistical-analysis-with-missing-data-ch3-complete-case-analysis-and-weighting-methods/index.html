<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>King Fox And Butterfly</title>
<meta name="description" content="A blog about cooking and statistics.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="http://liyingbo.com/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="http://liyingbo.com/css/font-awesome.min.css">
<link rel="stylesheet" href="http://liyingbo.com/css/owl.carousel.css">
<link rel="stylesheet" href="http://liyingbo.com/css/owl.theme.css">


  <link href="http://liyingbo.com/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="http://liyingbo.com/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="http://liyingbo.com/img/favicon.png">


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-116913878-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="http://liyingbo.com">King Fox And Butterfly</a></h1>
    
      <p class="sidebar-p">I am a home cook and statistian, both with more than 10 years of experience.</p>
    
      <p class="sidebar-p">Originally from Shanghai, currently based in Dallas.</p>
    
    <ul class="sidebar-menu">
      
        <li><a href="http://liyingbo.com/cooking/">Cooking</a></li>
      
        <li><a href="http://liyingbo.com/stat/">Statistics</a></li>
      
        <li><a href="http://liyingbo.com/about/">About Me</a></li>
      
        <li><a href="http://liyingbo.com/categories/">Categories</a></li>
      
        <li><a href="http://liyingbo.com/tags/">Tags</a></li>
      
    </ul>
    <p class="social">
  
  
  
  
  
  
  <a href="https://www.linkedin.com/in/yingbo-li-08321723/" data-animate-hover="pulse" class="external">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  
  <a href="https://github.com/yingboli" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
</p>


    <div class="copyright">
      <p class="credit">
        
          &copy; Yingbo Li 2018 -- 2021 |
        
        Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="http://liyingbo.com">King Fox And Butterfly</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Book Notes: Statistical Analysis with Missing Data -- Ch3 Complete Case Analysis and Weighting Methods</h1>
         

<div id="TOC">
<ul>
<li><a href="#weighted-complete-case-analysis">Weighted Complete-Case Analysis</a></li>
<li><a href="#available-case-analysis">Available-Case Analysis</a></li>
</ul>
</div>

<p><strong><em>For the pdf slides, click <a href="/pdf/090720_missing_data_book_ch3.pdf">here</a></em></strong></p>
<div id="complete-case-cc-analysis" class="section level3">
<h3>Complete-case (CC) analysis</h3>
<ul>
<li><p><font color='blue'>Complete-case (CC) analysis</font>: use only data points (units) where all variables are observed</p></li>
<li><p>Loss of information in CC analysis:</p>
<ul>
<li>Loss of precision (larger variance)</li>
<li>Bias, when the missingness mechanism is not MCAR. In this case, the complete units are not a random sample of the population</li>
</ul></li>
<li><p>In this notes, I will focus on the bias issue</p>
<ul>
<li>Adjusting for the CC analysis bias using weights</li>
<li>This idea is closed related to weighting in randomization inference for finite population surveys</li>
</ul></li>
</ul>
</div>
<div id="weighted-complete-case-analysis" class="section level1">
<h1>Weighted Complete-Case Analysis</h1>
<div id="notations" class="section level3">
<h3>Notations</h3>
<ul>
<li>Population size <span class="math inline">\(N\)</span>, sample size <span class="math inline">\(n\)</span></li>
<li>Number of variables (items): <span class="math inline">\(K\)</span></li>
<li>Data: <span class="math inline">\(Y=(y_{ij})\)</span>, where <span class="math inline">\(i = 1, \ldots, N\)</span> and <span class="math inline">\(j = 1, \ldots, K\)</span></li>
<li>Design information (about sampling or missingness): <span class="math inline">\(Z\)</span></li>
<li><p>Sample indicator: <span class="math inline">\(I = (I_1, \ldots, I_N)&#39;\)</span>; for unit <span class="math inline">\(i\)</span>,
<span class="math display">\[
I_i = \mathbf{1}_{\{\text{unit } i \text{ included in the sample}\}}
\]</span></p></li>
<li><p>Sample selection processes can be characterized by a distribution for <span class="math inline">\(I\)</span> given <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>.</p></li>
</ul>
</div>
<div id="probability-sampling" class="section level3">
<h3>Probability sampling</h3>
<ul>
<li><p>Properties of <font color='blue'>probability sampling</font></p>
<ol style="list-style-type: decimal">
<li><p>Unconfounded: selection doesn’t depend on <span class="math inline">\(Y\)</span>, i.e.,
<span class="math display">\[
  f(I \mid Y, Z) = f(I \mid Z)
  \]</span></p></li>
<li><p>Every unit has a positive (known) probability of selection
<span class="math display">\[
  \pi_i = P(I_i = 1 \mid Z) &gt; 0, \quad \text{for all } i
  \]</span></p></li>
</ol></li>
<li><p>In <font color='blue'>equal probability sample design</font>, <span class="math inline">\(\pi_i\)</span> is the same for all <span class="math inline">\(i\)</span></p></li>
</ul>
</div>
<div id="stratified-random-sampling" class="section level3">
<h3>Stratified random sampling</h3>
<ul>
<li><p><span class="math inline">\(Z\)</span> is a variable defining strata. Suppose Stratum <span class="math inline">\(Z=j\)</span> has <span class="math inline">\(N_j\)</span> units in total,
for <span class="math inline">\(j= 1, \ldots, J\)</span></p></li>
<li><p>In Stratum <span class="math inline">\(j\)</span>, <font color='blue'>stratified random sampling</font> takes a simple random sample of <span class="math inline">\(n_j\)</span> units</p></li>
<li><p>The distribution of <span class="math inline">\(I\)</span> under stratified random sampling is
<span class="math display">\[
f(I \mid Z) = \prod_{j=1}^J {N_j \choose n_j}^{-1}
\]</span></p></li>
</ul>
</div>
<div id="example-estimating-population-mean-bary" class="section level3">
<h3><font color='green'>Example: estimating population mean</font> <span class="math inline">\(\bar{Y}\)</span></h3>
<ul>
<li><p>An unbiased estimate is the stratified sample mean
<span class="math display">\[
\bar{y}_{\text{st}} = \frac{\sum_{j=1}^J N_j \bar{y}_j}{N}
\]</span>
where <span class="math inline">\(\bar{y}_j\)</span> is the sample mean in stratum <span class="math inline">\(j\)</span></p></li>
<li><p>Sampling variance approximation
<span class="math display">\[
v(\bar{y}_{st}) \approx \frac{1}{N^2} \sum_{j=1}^J N_j^2 
\left(\frac{1}{n_j} - \frac{1}{N_j} \right)s_j^2
\]</span>
where <span class="math inline">\(s_j\)</span> is the sample variance of <span class="math inline">\(Y\)</span> in stratum <span class="math inline">\(j\)</span></p></li>
<li><p>A large sample 95% confidence interval for <span class="math inline">\(\bar{Y}\)</span> is
<span class="math display">\[
\bar{y}_{\text{st}} \pm 1.96 \sqrt{v(\bar{y}_{st})}
\]</span></p></li>
</ul>
</div>
<div id="weighting-methods" class="section level3">
<h3>Weighting methods</h3>
<ul>
<li><p><font color='red'>Main idea: A unit selected with probability</font> <span class="math inline">\(\pi_i\)</span> <font color='red'>is “representing”</font> <span class="math inline">\(\pi_i^{-1}\)</span> <font color='red'>units in the population, hence should be given weights</font> <span class="math inline">\(\pi_i^{-1}\)</span>.</p></li>
<li><p>For example, in stratified random sample</p>
<ul>
<li>A selected unit <span class="math inline">\(i\)</span> in stratum <span class="math inline">\(j\)</span> represents <span class="math inline">\(N_j/n_j\)</span> population units</li>
<li>Thus by <font color='blue'>Horvitz-Thompson estimate</font>, the population mean can be estimated by the weighted sum
<span class="math display">\[
  \bar{y}_w = \frac{1}{n}\sum_{i=1}^n w_i y_i, \quad 
  \pi_i = \frac{n_j}{N_j}, \quad w_i = n \cdot \frac{\pi_i^{-1}}{\sum_k \pi_k^{-1}}
  \]</span></li>
<li>It is not hard to show that
<span class="math display">\[
  \bar{y}_w = \bar{y}_{\text{st}}
  \]</span></li>
</ul></li>
</ul>
</div>
<div id="weighting-with-nonresponses" class="section level3">
<h3>Weighting with nonresponses</h3>
<ul>
<li><p>If the probability of selecting unit <span class="math inline">\(i\)</span> is <span class="math inline">\(\pi_i\)</span>, and the probability of response for unit <span class="math inline">\(i\)</span> is <span class="math inline">\(\phi_i\)</span>, then
<span class="math display">\[
P(\text{unit } i \text{ is observed}) = \pi_i \phi_i
\]</span></p></li>
<li><p>Suppose there are <span class="math inline">\(r\)</span> units observed (respondents). Then the weighted estimate for <span class="math inline">\(\bar{Y}\)</span> is
<span class="math display">\[
\bar{y}_w = \frac{1}{r} \sum_{i=1}^r w_i y_i, \quad
w_i = r \cdot \frac{(\pi_i \phi_i)^{-1}}{\sum_k (\pi_k \phi_k)^{-1}}
\]</span></p></li>
<li><p>Usually <span class="math inline">\(\phi_i\)</span> is unknown and thus needs to be estimated</p></li>
</ul>
</div>
<div id="weighting-class-estimator" class="section level3">
<h3><font color='blue'>Weighting class estimator</font></h3>
<ul>
<li><p>Weighting class adjustments are used primarily to handle unit nonresponse</p></li>
<li><p>Suppose we partition the sample into <span class="math inline">\(J\)</span> “weighting classes”.
In the weighting class <span class="math inline">\(C = j\)</span>:</p>
<ul>
<li><span class="math inline">\(n_j\)</span>: the sample size</li>
<li><span class="math inline">\(r_j\)</span>: number of observed samples</li>
<li>A simple estimator for <span class="math inline">\(\phi_j\)</span> is <span class="math inline">\(\hat{\phi}_j = \frac{r_j}{n_j}\)</span></li>
</ul></li>
<li><p>For equal probability designs, where <span class="math inline">\(\pi_i\)</span> is constant,
the weighting class estimator is
<span class="math display">\[
\bar{y}_{\text{wc}} = \frac{1}{n}\sum_{j=1}^J n_j \bar{y}_{j\text{R}}
\]</span>
where <span class="math inline">\(\bar{y}_{j\text{R}}\)</span> is the respondent mean in class <span class="math inline">\(j\)</span></p></li>
<li><p>The estimate is unbiased under the following form of MAR assumption
<font color='red'>(Quasirandomization)</font>: data are MCAR within weighting class <span class="math inline">\(j\)</span></p></li>
</ul>
</div>
<div id="more-about-weighting-class-adjustments" class="section level3">
<h3>More about weighting class adjustments</h3>
<ul>
<li><p><font color='green'>Pros</font>: handle bias with one set of weights for multivariate <span class="math inline">\(Y\)</span></p></li>
<li><p><font color='red'>Cons</font>: weighting is inefficient and can increase in sampling variance,
if <span class="math inline">\(Y\)</span> is weakly related to the weighting class variable <span class="math inline">\(C\)</span></p></li>
<li><p>How to choose weighting class adjustments: weighting is only effective for outcomes (<span class="math inline">\(Y\)</span>) that are associated with the adjustment cell variable (<span class="math inline">\(C\)</span>). See the right column in the table below.</p></li>
</ul>
<p><img src="/figures/Little_Rubin_book_tb3_1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="propensity-weighting" class="section level3">
<h3>Propensity weighting</h3>
<ul>
<li><p>The theory of propensity scores provides a prescription for choosing the coarsest reduction of <span class="math inline">\(X\)</span> to a weighting class variable <span class="math inline">\(C\)</span> so that quasirandomization is roughly satisfied</p></li>
<li><p>Let <span class="math inline">\(X\)</span> denote the variables observed for both respondents and nonrespondents</p></li>
<li><p>Suppose data are MAR, with <span class="math inline">\(\phi\)</span> being unknown parameters about missing mechanism
<span class="math display">\[
P(M \mid X, Y, \phi) = P(M \mid X, \phi)
\]</span>
Then quasirandomization is satisfied when <span class="math inline">\(C\)</span> is chosen to be <span class="math inline">\(X\)</span></p></li>
</ul>
</div>
<div id="response-propensity-stratification" class="section level3">
<h3>Response propensity stratification</h3>
<ul>
<li><p>Define <font color='blue'>response propensity</font> for unit <span class="math inline">\(i\)</span> as
<span class="math display">\[
\rho(x_i, \phi) = P\left(m_i = 0 \mid \rho(x_i, \phi), \phi\right)
\]</span>
i.e., <font color='green'>respondents are a random subsample within strata defined by the propensity score</font> <span class="math inline">\(\rho(X, \phi)\)</span></p></li>
<li><p>Usually <span class="math inline">\(\phi\)</span> is unknown. So <strong>a practical procedure</strong> is</p>
<ol style="list-style-type: lower-roman">
<li>Estimate <span class="math inline">\(\hat{\phi}\)</span> from a binary regression of <span class="math inline">\(M\)</span> on <span class="math inline">\(X\)</span>,
based on respondent and nonrespondent data</li>
<li>Let <span class="math inline">\(C\)</span> be a grouped variable by coarsening <span class="math inline">\(\rho\left(X, \hat{\phi}\right)\)</span> into 5 or 10 values</li>
</ol></li>
<li><p>Thus, within the same adjustment class, all respondents and nonrespondents have the same value of the grouped propensity score</p></li>
</ul>
</div>
<div id="an-alternative-procedure-propensity-weighting" class="section level3">
<h3>An alternative procedure: propensity weighting</h3>
<ul>
<li><p>An alternative procedure is to weight respondents <span class="math inline">\(i\)</span> directly by the inverse propensity score <span class="math inline">\(\rho\left(X, \hat{\phi}\right)^{-1}\)</span></p></li>
<li><p><font color='green'>This method removes nonresponse bias</font></p></li>
<li><p><font color='red'>But it may yield estimates with extremely high sampling variance because respondents with very low estimated response propensities receive large nonresponse weights</font></p></li>
<li><p><font color='red'>Also, weighting directly by inverse propensities place may reliance on correct model specification of the regression of <span class="math inline">\(M\)</span> on <span class="math inline">\(X\)</span></font></p></li>
</ul>
</div>
<div id="example-inverse-probability-weighted-generalized-estimating-equations-gee" class="section level3">
<h3><font color='green'>Example: inverse probability weighted generalized estimating equations (GEE)</font></h3>
<ul>
<li><p>Let <span class="math inline">\(x_i\)</span> be covariates of GEE, and <span class="math inline">\(z_i\)</span> be a fully observed vector that can predict missing mechanism</p></li>
<li><p>If <span class="math inline">\(P(m_i = 1 \mid x_i, y_i, z_i, \phi) = P(m_i = 1 \mid x_i, \phi)\)</span>, then
the unweighted completed case GEE is unbiased
<span class="math display">\[
\sum_{i=1}^r D_i(x_i, \beta)\left[y_i - g(x_i, \beta)\right] = 0
\]</span></p></li>
<li><p>If <span class="math inline">\(P(m_i = 1 \mid x_i, y_i, z_i, \phi) = P(m_i = 1 \mid x_i, z_i, \phi)\)</span>, then
the inverse probability weighted GEE is unbiased
<span class="math display">\[
\sum_{i=1}^r w_i(\hat{\alpha}) D_i(x_i, \beta)\left[y_i - g(x_i, \beta)\right] = 0, \quad
w_i(\hat{\alpha}) = \frac{1}{p(x_i, z_i \mid \hat{\alpha})}
\]</span>
where <span class="math inline">\(p(x_i, z_i \mid \hat{\alpha})\)</span> is the probability of being a complete unit,
based on logistic regression of <span class="math inline">\(m_i\)</span> on <span class="math inline">\(x_i, z_i\)</span></p></li>
</ul>
</div>
<div id="poststratification" class="section level3">
<h3>Poststratification</h3>
<ul>
<li><p>The weighting class estimator
<span class="math display">\[
\bar{y}_{\text{wc}} = \frac{1}{n}\sum_{j=1}^J n_j \bar{y}_{j\text{R}}
\]</span>
uses the sample proportion <span class="math inline">\(n_j/n\)</span> to estimate the population proportion <span class="math inline">\(N_j/N\)</span>.</p></li>
<li><p>If from an external resource (e.g., census or a large survey),
we know the population proportion of weighting classes, then we can use the post stratified mean to estimate <span class="math inline">\(\bar{Y}\)</span>:
<span class="math display">\[
\bar{y}_{\text{ps}} = \frac{1}{N}\sum_{j=1}^J N_j \bar{y}_{j\text{R}}
\]</span></p></li>
</ul>
</div>
<div id="summary-of-weighting-methods" class="section level3">
<h3>Summary of weighting methods</h3>
<ul>
<li><p>Weighted CC estimates are often simple to compute,
but the appropriate standard errors can be hard to compute (even asymptotically)</p></li>
<li><p>Weighting methods treat weights as fixed and known,
but these nonresponse weights are computed from observed data and hence are subject to sampling uncertainty</p></li>
<li><p>Because weighted CC methods discard incomplete units and do not provide an automatic control of sampling variance, they are most useful when</p>
<ul>
<li>Number of covariates is small, and</li>
<li>Sample size is large</li>
</ul></li>
</ul>
</div>
</div>
<div id="available-case-analysis" class="section level1">
<h1>Available-Case Analysis</h1>
<div id="available-case-ac-analysis" class="section level3">
<h3>Available-case (AC) analysis</h3>
<ul>
<li><p><font color='blue'>Available-case analysis</font>: for univariate analysis, include all unites where that variable is present</p>
<ul>
<li>Sample changes from variable to variable according to the pattern of missing data</li>
<li>This is problematic if not MCAR</li>
<li>Under MCAR, AC can be used to estimate mean and variance for a single variable</li>
</ul></li>
<li><p><font color='blue'>Pairwise AC</font>: estimates covariance of <span class="math inline">\(Y_j\)</span> and <span class="math inline">\(Y_k\)</span> based on units <span class="math inline">\(i\)</span> where both <span class="math inline">\(y_{ij}\)</span> and <span class="math inline">\(y_{ik}\)</span> are observed</p>
<ul>
<li>Pairwise covariance estimator:
<span class="math display">\[
  s_{jk}^{(jk)} = \sum_{i \in I_{jk}} 
  \left( y_{ij} - \bar{y}_j^{(jk)} \right)
  \left( y_{ik} - \bar{y}_k^{(jk)} \right)/ \left( n^{(jk)} - 1 \right)
  \]</span>
where <span class="math inline">\(I_{jk}\)</span> is the set of <span class="math inline">\(n^{(jk)}\)</span> units with both <span class="math inline">\(Y_j\)</span> and <span class="math inline">\(Y_k\)</span> observed</li>
</ul></li>
</ul>
</div>
<div id="problems-with-pairwise-ac-estimators-on-correlation" class="section level3">
<h3>Problems with pairwise AC estimators on correlation</h3>
<ul>
<li><p>Correlation estimator 1:
<span class="math display">\[
r_{jk}^* = \frac{s_{jk}^{(jk)}}{\sqrt{s_{jj}^{(j)} s_{kk}^{(k)}}}
\]</span></p>
<ul>
<li><font color='red'>Problem: it can lie outside of <span class="math inline">\((-1, 1)\)</span></font></li>
</ul></li>
<li><p>Correlation estimator 2 corrects the previous problem:
<span class="math display">\[
r_{jk}^{(jk)} = \frac{s_{jk}^{(jk)}}{\sqrt{s_{jj}^{(jk)} s_{kk}^{(jk)}}}
\]</span></p></li>
<li><p><font color='green'>Under MCAR, all these estimators on covariance and correlation are consistent</font></p></li>
<li><p><font color='red'>However, when <span class="math inline">\(K &gt; 3\)</span>, both correlation estimators can yield correlation matrices that are not positive definite!</font></p>
<ul>
<li>An extreme example: <span class="math inline">\(r_{12} = 1, r_{13} = 1, r_{23} = -1\)</span></li>
</ul></li>
</ul>
</div>
<div id="compare-cc-and-ac-methods" class="section level3">
<h3>Compare CC and AC methods</h3>
<ul>
<li><p>When data is MCAR and correlations are mild, AC methods are more efficient than CC</p></li>
<li><p>When correlations are large, CC methods are usually better</p></li>
</ul>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<ul>
<li>Little, R. J., &amp; Rubin, D. B. (2019). Statistical Analysis with Missing Data, 3rd Edition. John Wiley &amp; Sons.</li>
</ul>
</div>
</div>

         <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "kfab" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="http://liyingbo.com/js/jquery.min.js"></script>
<script src="http://liyingbo.com/js/bootstrap.min.js"></script>
<script src="http://liyingbo.com/js/jquery.cookie.js"> </script>
<script src="http://liyingbo.com/js/ekko-lightbox.js"></script>
<script src="http://liyingbo.com/js/jquery.scrollTo.min.js"></script>
<script src="http://liyingbo.com/js/masonry.pkgd.min.js"></script>
<script src="http://liyingbo.com/js/imagesloaded.pkgd.min.js"></script>
<script src="http://liyingbo.com/js/owl.carousel.min.js"></script>
<script src="http://liyingbo.com/js/front.js"></script>




<script>
    MathJax = {
        tex: {
            macros: {
                E: ['\\mathbf{E}'],
                V: ['\\mathbf{Var}'],
                C: ['\\mathbf{Cov}'],
                AV: ['\\mathbf{AVar}']
            }
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

</body>
</html>
